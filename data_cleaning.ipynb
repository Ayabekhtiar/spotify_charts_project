{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Cleaning Pipeline\n",
                "\n",
                "This notebook executes the data cleaning and merging process using the `data_cleaning` module."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os \n",
                "import pandas as pd\n",
                "\n",
                "import pathlib\n",
                "import numpy as np\n",
                "\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting data processing...\n",
                        "✓ File saved as: data/bronze/combined_songs.csv\n",
                        "Data processing complete.\n",
                        "Starting data merging...\n",
                        "✓ Merged data saved to: data/silver/songs_with_features.csv\n",
                        "Data merging complete.\n",
                        "Songs loaded successfully. (41_995 rows)\n"
                    ]
                }
            ],
            "source": [
                "from data_cleaning.process_charts import process_all_charts\n",
                "from data_cleaning.merge import merge_data\n",
                "from data_cleaning.clean_songs import (\n",
                "    list_weekly_chart_files,\n",
                "    extract_dates_from_filenames,\n",
                "    summarize_weekly_date_gaps,\n",
                "    create_song_dict,\n",
                "    update_song_rows_with_dict,\n",
                "    fill_with_proxy_dict_compat,\n",
                "    fill_missing_from_dfs,\n",
                ")\n",
                "\n",
                "DATA_DIR = \"data\"\n",
                "\n",
                "weekly_charts_path = os.path.join(DATA_DIR, \"bronze\", \"data\")\n",
                "tracks_path = os.path.join(DATA_DIR, \"bronze\", \"tracks.csv\")\n",
                "songs_path = os.path.join(DATA_DIR, \"bronze\", \"combined_songs.csv\")\n",
                "output_path = os.path.join(DATA_DIR, \"silver\", \"songs_with_features.csv\")\n",
                "\n",
                "print(\"Starting data processing...\")\n",
                "process_all_charts(weekly_charts_path, songs_path)\n",
                "\n",
                "print(\"Data processing complete.\")\n",
                "\n",
                "print(\"Starting data merging...\")\n",
                "merge_data(tracks_path, songs_path, output_path)\n",
                "print(\"Data merging complete.\")\n",
                "\n",
                "if os.path.exists(output_path):\n",
                "    songs = pd.read_csv(output_path)\n",
                "    print(\"Songs loaded successfully. ({:_} rows)\".format(songs.shape[0]))\n",
                "else:\n",
                "    raise FileNotFoundError(\"Error: Output path does not exist.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verification\n",
                "Check if no week was skipped during the webscraping."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "First date: 2016-12-29\n",
                        "Last date: 2020-12-31\n",
                        "Total files: 210\n",
                        "Expected weeks: 210\n",
                        "\n",
                        "Missing weeks:\n",
                        "\n",
                        "Unexpected extra dates:\n"
                    ]
                }
            ],
            "source": [
                "# Example usage of verification helpers from data_cleaning.clean_songs\n",
                "files = list_weekly_chart_files(weekly_charts_path)\n",
                "dates = extract_dates_from_filenames(files)\n",
                "summarize_weekly_date_gaps(dates)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Rows where name is not included in track_name: 0/41_995\n",
                        "Column 'name' dropped successfully.\n"
                    ]
                }
            ],
            "source": [
                "if \"name\" in songs.columns:\n",
                "    # flag where name not NaN and track_name is NaN\n",
                "    print(\"Rows where name is not included in track_name: {}/{:_}\".format(songs[songs[\"name\"].notna() & songs[\"track_name\"].isna()].shape[0], songs.shape[0]))\n",
                "    \n",
                "    # Drop the \"name\" column as it is included in \"track_name\"\n",
                "    songs.drop(columns=[\"name\"], inplace=True)\n",
                "    print(\"Column 'name' dropped successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Clean songs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(Index(['track_id', 'artist_names', 'track_name', 'source', 'week_date',\n",
                            "        'popularity', 'duration_ms', 'explicit', 'artists', 'id_artists',\n",
                            "        'release_date', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
                            "        'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
                            "        'valence', 'tempo', 'time_signature'],\n",
                            "       dtype='object'),\n",
                            " (41995, 23))"
                        ]
                    },
                    "execution_count": 73,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "songs.columns, songs.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing rows:   0%|          | 0/41995 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing rows: 100%|██████████| 41995/41995 [00:00<00:00, 59077.00it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['0VjIjW4GlUZAMYd2vXMi3b', 'Republic Records', Timestamp('2020-03-20 00:00:00')]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Create a dictionary of canonical song IDs using helper from data_cleaning.clean_songs\n",
                "song_dict = create_song_dict(songs)\n",
                "print(song_dict[(\"The Weeknd\", \"Blinding Lights\")])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Updating songs: 100%|██████████| 41995/41995 [00:05<00:00, 7387.32it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of songs updated: 6_458/41_995\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Apply the update function from data_cleaning.clean_songs\n",
                "songs = update_song_rows_with_dict(songs, song_dict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of rows filled: 11_069\n"
                    ]
                }
            ],
            "source": [
                "# Fill missing values in columns of interest using helpers from data_cleaning.clean_songs\n",
                "columns_to_fill = [\n",
                "    'artist_names', 'track_name', 'source', 'duration_ms', 'explicit', \n",
                "    'popularity', 'artists', 'id_artists', 'release_date', 'danceability', 'energy', \n",
                "    'key', 'loudness', 'mode', 'speechiness', 'acousticness', \n",
                "    'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'\n",
                "]\n",
                "\n",
                "songs = fill_with_proxy_dict_compat(songs, columns_to_fill)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "There are still 7_404 rows with NaN values\n"
                    ]
                }
            ],
            "source": [
                "print(\"There are still {:_} rows with NaN values\".format(songs[songs.isna().any(axis=1)].shape[0]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enrich still missing values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "((6513, 19),\n",
                            " Index(['track_id', 'artist_names', 'track_name', 'source', 'key', 'mode',\n",
                            "        'time_signature', 'danceability', 'energy', 'speechiness',\n",
                            "        'acousticness', 'instrumentalness', 'liveness', 'valence', 'loudness',\n",
                            "        'tempo', 'duration_ms', 'weeks_on_chart', 'streams'],\n",
                            "       dtype='object'))"
                        ]
                    },
                    "execution_count": 78,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_enrichment2_path = os.path.join(DATA_DIR, \"bronze\", \"spotify_top_songs_audio_features.csv\")\n",
                "df_enrichment2 = pd.read_csv(df_enrichment2_path)\n",
                "if \"id\" in df_enrichment2.columns:\n",
                "    # Replace id with track_id\n",
                "    df_enrichment2.rename(columns={\"id\": \"track_id\"}, inplace=True)\n",
                "df_enrichment2.shape, df_enrichment2.columns "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "((247035, 17),\n",
                            " Index(['artist_name', 'track_id', 'track_name', 'acousticness', 'danceability',\n",
                            "        'duration_ms', 'energy', 'instrumentalness', 'key', 'liveness',\n",
                            "        'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence',\n",
                            "        'popularity'],\n",
                            "       dtype='object'))"
                        ]
                    },
                    "execution_count": 79,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# List all dataframes in a kaggle_enrichment3_dir, then add them together to it is one big dataframe\n",
                "kaggle_enrichment3_dir = os.path.join(DATA_DIR, \"bronze\", \"kaggle_enrichment3\")\n",
                "import glob\n",
                "\n",
                "# List all CSV files in the kaggle_enrichment3_dir\n",
                "csv_files = glob.glob(os.path.join(kaggle_enrichment3_dir, \"*.csv\"))\n",
                "\n",
                "# Read each CSV file into a DataFrame and collect them in a list\n",
                "df_list = [pd.read_csv(f) for f in csv_files]\n",
                "\n",
                "# Concatenate all DataFrames into a single big DataFrame\n",
                "df_enrichment3 = pd.concat(df_list, ignore_index=True)\n",
                "\n",
                "# Show shape and columns to confirm final structure\n",
                "df_enrichment3.shape, df_enrichment3.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "({'streams', 'track_id', 'weeks_on_chart'}, {'artist_name', 'track_id'})"
                        ]
                    },
                    "execution_count": 80,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "set(df_enrichment2.columns).difference(set(columns_to_fill)), set(df_enrichment3.columns).difference(set(columns_to_fill))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total missing values *before* processing DF: 125_826\n",
                        "Available columns: ['artist_names', 'track_name', 'source', 'duration_ms', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
                        "Size of lookup dictionary : 6513\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Enriching songs: 100%|██████████| 41995/41995 [00:11<00:00, 3533.69it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Available columns: ['track_name', 'duration_ms', 'popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
                        "Size of lookup dictionary : 130989\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Enriching songs: 100%|██████████| 41995/41995 [00:03<00:00, 12609.75it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total missing values *after* processing DF: 33_889\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Enrich missing values from external enrichment DataFrames using helper from data_cleaning.clean_songs\n",
                "songs_gold = fill_missing_from_dfs(songs, columns_to_fill, \"track_id\", df_enrichment2, df_enrichment3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save songs_gold\n",
                "if \"popularity\" in songs_gold.columns:\n",
                "    songs_gold.drop(columns=[\"popularity\"], inplace=True)\n",
                "songs_gold.to_csv(os.path.join(DATA_DIR, \"gold\", \"songs_with_features.csv\"), index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>track_id</th>\n",
                            "      <th>artist_names</th>\n",
                            "      <th>track_name</th>\n",
                            "      <th>source</th>\n",
                            "      <th>week_date</th>\n",
                            "      <th>duration_ms</th>\n",
                            "      <th>explicit</th>\n",
                            "      <th>artists</th>\n",
                            "      <th>id_artists</th>\n",
                            "      <th>release_date</th>\n",
                            "      <th>...</th>\n",
                            "      <th>key</th>\n",
                            "      <th>loudness</th>\n",
                            "      <th>mode</th>\n",
                            "      <th>speechiness</th>\n",
                            "      <th>acousticness</th>\n",
                            "      <th>instrumentalness</th>\n",
                            "      <th>liveness</th>\n",
                            "      <th>valence</th>\n",
                            "      <th>tempo</th>\n",
                            "      <th>time_signature</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>25sgk305KZfyuqVBQIahim</td>\n",
                            "      <td>Ava Max</td>\n",
                            "      <td>Sweet but Psycho</td>\n",
                            "      <td>Atlantic Records</td>\n",
                            "      <td>2019-01-17</td>\n",
                            "      <td>187436.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>C#/Db</td>\n",
                            "      <td>-4.724</td>\n",
                            "      <td>Major</td>\n",
                            "      <td>0.0476</td>\n",
                            "      <td>0.0691</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.1660</td>\n",
                            "      <td>0.628</td>\n",
                            "      <td>133.002</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>7wFybC8jBH3zE139OpCtpG</td>\n",
                            "      <td>Gesaffelstein, The Weeknd</td>\n",
                            "      <td>Lost in the Fire (feat. The Weeknd)</td>\n",
                            "      <td>Columbia</td>\n",
                            "      <td>2019-01-17</td>\n",
                            "      <td>202093.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>D</td>\n",
                            "      <td>-12.159</td>\n",
                            "      <td>Major</td>\n",
                            "      <td>0.0359</td>\n",
                            "      <td>0.0863</td>\n",
                            "      <td>0.001330</td>\n",
                            "      <td>0.1170</td>\n",
                            "      <td>0.176</td>\n",
                            "      <td>101.004</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>56</th>\n",
                            "      <td>0jAfdqv18goRTUxm3ilRjb</td>\n",
                            "      <td>A Boogie Wit da Hoodie, Tyga, Offset</td>\n",
                            "      <td>Startender (feat. Offset and Tyga)</td>\n",
                            "      <td>Highbridge the Label / Atlantic Records</td>\n",
                            "      <td>2019-01-17</td>\n",
                            "      <td>192779.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>F#/Gb</td>\n",
                            "      <td>-4.653</td>\n",
                            "      <td>Minor</td>\n",
                            "      <td>0.1330</td>\n",
                            "      <td>0.0235</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.1510</td>\n",
                            "      <td>0.506</td>\n",
                            "      <td>191.971</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>57</th>\n",
                            "      <td>13hvHEstJ4sNbzdroPrPI3</td>\n",
                            "      <td>Dua Lipa, BLACKPINK</td>\n",
                            "      <td>Kiss and Make Up</td>\n",
                            "      <td>Warner Records</td>\n",
                            "      <td>2019-01-17</td>\n",
                            "      <td>190560.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>['Dua Lipa', 'BLACKPINK']</td>\n",
                            "      <td>['6M2wZ9GZgrQXHCFfjv46we', '41MozSoPIsD1dJM0CL...</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>-4.383</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.1460</td>\n",
                            "      <td>0.0557</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.1890</td>\n",
                            "      <td>0.630</td>\n",
                            "      <td>99.986</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>62</th>\n",
                            "      <td>2FUNBaa5DwItJtYEBgAblU</td>\n",
                            "      <td>21 Savage</td>\n",
                            "      <td>monster</td>\n",
                            "      <td>Slaughter Gang, LLC/Epic Records</td>\n",
                            "      <td>2019-01-17</td>\n",
                            "      <td>233040.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>A</td>\n",
                            "      <td>-6.916</td>\n",
                            "      <td>Minor</td>\n",
                            "      <td>0.1240</td>\n",
                            "      <td>0.1580</td>\n",
                            "      <td>0.000228</td>\n",
                            "      <td>0.1180</td>\n",
                            "      <td>0.224</td>\n",
                            "      <td>134.022</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>41943</th>\n",
                            "      <td>7K7MUBCnzgBAvMVW2RTWNs</td>\n",
                            "      <td>Loud Luxury, Brando</td>\n",
                            "      <td>Body</td>\n",
                            "      <td>Armada Music</td>\n",
                            "      <td>2019-06-13</td>\n",
                            "      <td>163216.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>C#/Db</td>\n",
                            "      <td>-4.399</td>\n",
                            "      <td>Major</td>\n",
                            "      <td>0.0380</td>\n",
                            "      <td>0.0476</td>\n",
                            "      <td>0.000094</td>\n",
                            "      <td>0.0543</td>\n",
                            "      <td>0.582</td>\n",
                            "      <td>121.958</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>41951</th>\n",
                            "      <td>6fxVffaTuwjgEk5h9QyRjy</td>\n",
                            "      <td>Ed Sheeran</td>\n",
                            "      <td>Photograph</td>\n",
                            "      <td>Atlantic Records UK</td>\n",
                            "      <td>2019-06-13</td>\n",
                            "      <td>258987.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>['Ed Sheeran']</td>\n",
                            "      <td>['6eUKZXaKkcviH0Ku9w2n3V']</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>-10.480</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0476</td>\n",
                            "      <td>0.6070</td>\n",
                            "      <td>0.000464</td>\n",
                            "      <td>0.0986</td>\n",
                            "      <td>0.201</td>\n",
                            "      <td>107.989</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>41978</th>\n",
                            "      <td>5s8LepdwU0THzpd0M7nLsa</td>\n",
                            "      <td>Ozuna</td>\n",
                            "      <td>Te Soñé de Nuevo</td>\n",
                            "      <td>Aura Music Corp.</td>\n",
                            "      <td>2019-06-13</td>\n",
                            "      <td>199813.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>G</td>\n",
                            "      <td>-2.867</td>\n",
                            "      <td>Minor</td>\n",
                            "      <td>0.1070</td>\n",
                            "      <td>0.0533</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0936</td>\n",
                            "      <td>0.773</td>\n",
                            "      <td>168.040</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>41986</th>\n",
                            "      <td>4Sokm1cWK36H2WctWWRGf1</td>\n",
                            "      <td>Ufo361</td>\n",
                            "      <td>Irina Shayk</td>\n",
                            "      <td>Stay High</td>\n",
                            "      <td>2019-06-13</td>\n",
                            "      <td>147452.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>D</td>\n",
                            "      <td>-9.504</td>\n",
                            "      <td>Minor</td>\n",
                            "      <td>0.0696</td>\n",
                            "      <td>0.1660</td>\n",
                            "      <td>0.020900</td>\n",
                            "      <td>0.1700</td>\n",
                            "      <td>0.201</td>\n",
                            "      <td>74.869</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>41994</th>\n",
                            "      <td>5AiqL0ezAAauDuVK5EJvXU</td>\n",
                            "      <td>Fero47</td>\n",
                            "      <td>NENENE</td>\n",
                            "      <td>Epic Germany</td>\n",
                            "      <td>2019-06-13</td>\n",
                            "      <td>183133.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>...</td>\n",
                            "      <td>F#/Gb</td>\n",
                            "      <td>-4.831</td>\n",
                            "      <td>Minor</td>\n",
                            "      <td>0.0887</td>\n",
                            "      <td>0.0307</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.1310</td>\n",
                            "      <td>0.760</td>\n",
                            "      <td>130.004</td>\n",
                            "      <td>4 beats</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>7404 rows × 22 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                     track_id                          artist_names  \\\n",
                            "5      25sgk305KZfyuqVBQIahim                               Ava Max   \n",
                            "11     7wFybC8jBH3zE139OpCtpG             Gesaffelstein, The Weeknd   \n",
                            "56     0jAfdqv18goRTUxm3ilRjb  A Boogie Wit da Hoodie, Tyga, Offset   \n",
                            "57     13hvHEstJ4sNbzdroPrPI3                   Dua Lipa, BLACKPINK   \n",
                            "62     2FUNBaa5DwItJtYEBgAblU                             21 Savage   \n",
                            "...                       ...                                   ...   \n",
                            "41943  7K7MUBCnzgBAvMVW2RTWNs                   Loud Luxury, Brando   \n",
                            "41951  6fxVffaTuwjgEk5h9QyRjy                            Ed Sheeran   \n",
                            "41978  5s8LepdwU0THzpd0M7nLsa                                 Ozuna   \n",
                            "41986  4Sokm1cWK36H2WctWWRGf1                                Ufo361   \n",
                            "41994  5AiqL0ezAAauDuVK5EJvXU                                Fero47   \n",
                            "\n",
                            "                                track_name  \\\n",
                            "5                         Sweet but Psycho   \n",
                            "11     Lost in the Fire (feat. The Weeknd)   \n",
                            "56      Startender (feat. Offset and Tyga)   \n",
                            "57                        Kiss and Make Up   \n",
                            "62                                 monster   \n",
                            "...                                    ...   \n",
                            "41943                                 Body   \n",
                            "41951                           Photograph   \n",
                            "41978                     Te Soñé de Nuevo   \n",
                            "41986                          Irina Shayk   \n",
                            "41994                               NENENE   \n",
                            "\n",
                            "                                        source   week_date  duration_ms  \\\n",
                            "5                             Atlantic Records  2019-01-17     187436.0   \n",
                            "11                                    Columbia  2019-01-17     202093.0   \n",
                            "56     Highbridge the Label / Atlantic Records  2019-01-17     192779.0   \n",
                            "57                              Warner Records  2019-01-17     190560.0   \n",
                            "62            Slaughter Gang, LLC/Epic Records  2019-01-17     233040.0   \n",
                            "...                                        ...         ...          ...   \n",
                            "41943                             Armada Music  2019-06-13     163216.0   \n",
                            "41951                      Atlantic Records UK  2019-06-13     258987.0   \n",
                            "41978                         Aura Music Corp.  2019-06-13     199813.0   \n",
                            "41986                                Stay High  2019-06-13     147452.0   \n",
                            "41994                             Epic Germany  2019-06-13     183133.0   \n",
                            "\n",
                            "       explicit                    artists  \\\n",
                            "5           NaN                       None   \n",
                            "11          NaN                       None   \n",
                            "56          NaN                       None   \n",
                            "57          0.0  ['Dua Lipa', 'BLACKPINK']   \n",
                            "62          NaN                       None   \n",
                            "...         ...                        ...   \n",
                            "41943       NaN                       None   \n",
                            "41951       0.0             ['Ed Sheeran']   \n",
                            "41978       NaN                       None   \n",
                            "41986       NaN                       None   \n",
                            "41994       NaN                       None   \n",
                            "\n",
                            "                                              id_artists release_date  ...  \\\n",
                            "5                                                   None         None  ...   \n",
                            "11                                                  None         None  ...   \n",
                            "56                                                  None         None  ...   \n",
                            "57     ['6M2wZ9GZgrQXHCFfjv46we', '41MozSoPIsD1dJM0CL...         None  ...   \n",
                            "62                                                  None         None  ...   \n",
                            "...                                                  ...          ...  ...   \n",
                            "41943                                               None         None  ...   \n",
                            "41951                         ['6eUKZXaKkcviH0Ku9w2n3V']         None  ...   \n",
                            "41978                                               None         None  ...   \n",
                            "41986                                               None         None  ...   \n",
                            "41994                                               None         None  ...   \n",
                            "\n",
                            "         key  loudness   mode  speechiness acousticness  instrumentalness  \\\n",
                            "5      C#/Db    -4.724  Major       0.0476       0.0691          0.000000   \n",
                            "11         D   -12.159  Major       0.0359       0.0863          0.001330   \n",
                            "56     F#/Gb    -4.653  Minor       0.1330       0.0235          0.000000   \n",
                            "57       8.0    -4.383    1.0       0.1460       0.0557          0.000000   \n",
                            "62         A    -6.916  Minor       0.1240       0.1580          0.000228   \n",
                            "...      ...       ...    ...          ...          ...               ...   \n",
                            "41943  C#/Db    -4.399  Major       0.0380       0.0476          0.000094   \n",
                            "41951    4.0   -10.480    1.0       0.0476       0.6070          0.000464   \n",
                            "41978      G    -2.867  Minor       0.1070       0.0533          0.000000   \n",
                            "41986      D    -9.504  Minor       0.0696       0.1660          0.020900   \n",
                            "41994  F#/Gb    -4.831  Minor       0.0887       0.0307          0.000000   \n",
                            "\n",
                            "       liveness  valence    tempo  time_signature  \n",
                            "5        0.1660    0.628  133.002         4 beats  \n",
                            "11       0.1170    0.176  101.004         4 beats  \n",
                            "56       0.1510    0.506  191.971         4 beats  \n",
                            "57       0.1890    0.630   99.986             4.0  \n",
                            "62       0.1180    0.224  134.022         4 beats  \n",
                            "...         ...      ...      ...             ...  \n",
                            "41943    0.0543    0.582  121.958         4 beats  \n",
                            "41951    0.0986    0.201  107.989             4.0  \n",
                            "41978    0.0936    0.773  168.040         4 beats  \n",
                            "41986    0.1700    0.201   74.869         4 beats  \n",
                            "41994    0.1310    0.760  130.004         4 beats  \n",
                            "\n",
                            "[7404 rows x 22 columns]"
                        ]
                    },
                    "execution_count": 83,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Show rows with NaN values in songs_gold\n",
                "songs_gold[songs_gold.isna().any(axis=1)]"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
