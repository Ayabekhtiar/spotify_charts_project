{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Cleaning Pipeline\n",
                "\n",
                "This notebook executes the data cleaning and merging process using the `data_cleaning` module."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting data processing...\n",
                        "✓ File saved as: /Users/arthurmrv/Library/Mobile Documents/com~apple~CloudDocs/Documents/School/AIDAMS/S5/data/project/spotify_charts_project/data/processed/combined_songs.csv\n",
                        "Data processing complete.\n",
                        "Starting data merging...\n",
                        "✓ Merged data saved to: data/processed/songs_with_features.csv\n",
                        "Data merging complete.\n"
                    ]
                }
            ],
            "source": [
                "from data_cleaning.process_charts import process_all_charts\n",
                "from data_cleaning.merge import merge_data\n",
                "\n",
                "weekly_charts_path = \"data/raw/data\"\n",
                "tracks_path = \"data/raw/tracks.csv\"\n",
                "songs_path = \"data/raw/combined_songs.csv\"\n",
                "output_path = \"data/processed/songs_with_features.csv\"\n",
                "\n",
                "print(\"Starting data processing...\")\n",
                "process_all_charts(weekly_charts_path)\n",
                "\n",
                "print(\"Data processing complete.\")\n",
                "\n",
                "print(\"Starting data merging...\")\n",
                "merge_data(tracks_path, songs_path, output_path)\n",
                "print(\"Data merging complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verification\n",
                "Check if no week was skipped during the webscraping."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "First date: 2016-12-29\n",
                        "Last date: 2020-12-31\n",
                        "Total files: 210\n",
                        "Expected weeks: 210\n",
                        "\n",
                        "Missing weeks:\n",
                        "\n",
                        "Unexpected extra dates:\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "#folder = \"data/raw/data\"\n",
                "\n",
                "# 1. List all CSV filenames\n",
                "files = [f for f in os.listdir(weekly_charts_path) if f.endswith(\".csv\")]\n",
                "\n",
                "# 2. Extract dates from filenames\n",
                "dates = []\n",
                "for f in files:\n",
                "    try:\n",
                "        date_str = f.replace(\"regional-global-weekly-\", \"\").replace(\".csv\", \"\")\n",
                "        dates.append(pd.to_datetime(date_str))\n",
                "    except Exception as e:\n",
                "        print(\"Skipping invalid filename:\", f)\n",
                "\n",
                "# Sort dates\n",
                "dates = sorted(dates)\n",
                "\n",
                "# 3. Create expected weekly date range\n",
                "if dates:\n",
                "    start = dates[0]\n",
                "    end = dates[-1]\n",
                "    expected = pd.date_range(start=start, end=end, freq=\"W-THU\")\n",
                "    \n",
                "    # 4. Check differences\n",
                "    missing = expected.difference(dates)\n",
                "    extra = set(dates) - set(expected)\n",
                "    \n",
                "    print(\"First date:\", start.date())\n",
                "    print(\"Last date:\", end.date())\n",
                "    print(\"Total files:\", len(dates))\n",
                "    print(\"Expected weeks:\", len(expected))\n",
                "    \n",
                "    print(\"\\nMissing weeks:\")\n",
                "    for m in missing:\n",
                "        print(m.date())\n",
                "    \n",
                "    print(\"\\nUnexpected extra dates:\")\n",
                "    for e in sorted(extra):\n",
                "        print(e.date())\n",
                "else:\n",
                "    print(\"No data files found.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
